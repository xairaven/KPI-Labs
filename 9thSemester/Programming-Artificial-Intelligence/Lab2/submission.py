def parameters_inititalization(m):
  """
  Ця функція ініціалізує вектор-рядок випадкових дійсних значень ваг форми (1, m),
  отриманих з нормального розподілу та зсув (довільне дійсне значення)

  Параметри:
  m -- кількість вхідних ознак для кожного навчального прикладу

  Повертає:
  W -- вектор-рядок ваг форми (1, m)
  b -- зсув (скаляр)
  """

  # BEGIN_YOUR_CODE
  W = np.random.randn(1, m)
  b = 0.0
  return W, b

def forwardPropagate(X, W, b):
  """
  Ця функція обчислює лінійну комбінацію вхідних ознак та ваг, включаючи зсув

  Параметри:
  X -- вхідний вектор ознак форми (m, X_train.shape[1])
  W -- вектор-рядок ваг форми (1, m)
  b -- зсув моделі (скаляр)

  Повертає:
  z -- загальна зважена сума вхідних ознак, включаючи зсув
  y_hat -- прогноз моделі
  """

  # BEGIN_YOUR_CODE
  z = np.dot(W, X) + b
  y_hat = z # у лінійній регресії активація – ідентична функція
  return z, y_hat
  # END_YOUR_CODE

def cost(n, y_hat, y_true):
  """
  Ця функція обчислює середнє квадратичне відхилення на всьому навчальному наборі даних

  Параметри:
  n -- загальна кількість навчальних прикладів
  y_hat -- вихідне значення лінійної регресії
  y_true -- істинне значення залежної змінної

  Повертає:
  J -- середнє квадратичне відхилення на всьому навчальному наборі даних
  """

  # BEGIN_YOUR_CODE
  J = (1/n) * np.sum((y_hat - y_true)**2)
  return J
  # END_YOUR_CODE

def backwardPropagate(n, X, y_hat, y_true):
  """
  Ця функція обчислює градієнти цільвої функції відносно ваг та зсуву

  Параметри:
  n -- загальна кількість навчальних прикладів
  X -- вхідний вектор ознак форми (1, X_train.shape[1])
  y_hat --  вихідне значення лінійної регресії
  y_true -- істинне значення залежної змінної

  Повертає:
  dW --  градієнт цільової функції відносно ваг моделі
  db -- градієнт цільової функції відносно зсуву моделі
  """

  # BEGIN_YOUR_CODE
  error = y_hat - y_true
  dW = (2/n) * np.dot(error, X.T)
  db = (2/n) * np.sum(error)
  return dW, db
  # END_YOUR_CODE

def update(alpha, dW, db, W, b):
  """
  Ця функція оновлює навчальні параметри моделі (ваги та зсув ) у напрямку мінімізації цільової функції

  Параметри:
  alpha -- швидкість  навчання (крок навчання)
  dW --  градієнт цільової функції відносно ваг моделі
  db -- градієнт цільової функції відносно зсуву моделі
  W -- вектор-рядок ваг моделі форми (1, m)
  b -- зсув моделі (скаляр)

  Повертає:
  W -- оновлений вектор-рядок ваг моделі форми (1, m)
  b -- оновлений зсув моделі (скаляр)
  """


  # BEGIN_YOUR_CODE
  W = W - alpha * dW
  b = b - alpha * db
  return W, b
  # END_YOUR_CODE
